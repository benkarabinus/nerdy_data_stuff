{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>__Assignment 5__</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load the required packages\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\tUpload the income_evaluation_cat.csv provided on canvas.  The features in this data include workclass, education, race, and gender. The output variable is income and contains two categorical values (<=50k or >50k) indicating whether the income of an individual is less than/equal to $50,000 or greater than $50,000 respectively. Print the unique values of each variable in this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " workclass\n",
      "[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked']\n",
      " education\n",
      "[' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n",
      " ' Assoc-acdm' ' Assoc-voc' ' 7th-8th' ' Doctorate' ' Prof-school'\n",
      " ' 5th-6th' ' 10th' ' 1st-4th' ' Preschool' ' 12th']\n",
      " race\n",
      "[' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other']\n",
      "gender\n",
      "[' Male' ' Female']\n",
      " income\n",
      "[' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"load income_evaluation_cat.csv\"\"\"\n",
    "\n",
    "income_evaluation_cat = pd.read_csv('income_evaluation_cat.csv')\n",
    "# print unique values in each column\n",
    "for col in income_evaluation_cat.columns:\n",
    "    print(col)\n",
    "    print(income_evaluation_cat[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\tYou will implement Naïve Bayes from scratch using Bayes’ rule. You can do your calculations in Python, but you would not use the sklearn package. Suppose that all the income_evaluation_cat.csv data you uploaded is the training data , classify a test instance, X = [“Private”, “Bachelors”, “White”, “Female”] into the class income<=50 or income>50k. You need to compute the posterior probabilities P(income<=50/X) and P(income>50k/X), then print the class with the greater posterior probability as the predicted class. You don’t need to define a function, but you could if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"clean the text  data in each column\"\"\"\n",
    "\n",
    "# strip the whitespace from the column names in the data\n",
    "income_evaluation_cat.columns = income_evaluation_cat.columns.str.strip()\n",
    "# get column names from the datarame\n",
    "colnames = income_evaluation_cat.columns\n",
    "# strip whitespace from each attribute value\n",
    "for col in colnames:\n",
    "    income_evaluation_cat[col] = income_evaluation_cat[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<=50'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"define Naive Bays classifier function\"\"\"\n",
    "\n",
    "def naive_bays_classifier(data, target, new_record):\n",
    "\n",
    "    # instantiate a list to store probabilities\n",
    "    probs_less_50K = []\n",
    "    probs_greater_50K = []\n",
    "    # get record attributes form the test set\n",
    "    attributes = data.columns.tolist()\n",
    "    # compute the probability of observing the new_record attributes int the data\n",
    "    for i in range(len(data.columns.tolist())-2):\n",
    "        attribute = new_record[i]\n",
    "        # compute the probability of observing the attribute given income <=50K\n",
    "        less_50_k_prob = data[(data[target] == '<=50K') & (data[attributes[i]] == attribute)].shape[0]\\\n",
    "                              / data.shape[0]\n",
    "        # append the probability for the attribute\n",
    "        probs_less_50K.append(less_50_k_prob)\n",
    "        # compute the probability of observing the attribute given income >50K\n",
    "        greater_50_k_prob = data[(data[target] == '>50K') & (data[attributes[i]] == attribute)].shape[0]\\\n",
    "                              / data.shape[0]\n",
    "        # append the probability for the attribute\n",
    "        probs_greater_50K.append(greater_50_k_prob)\n",
    "\n",
    "    # take product of y_value probability and likelhood of y_value/attribute combination\n",
    "    less_50 = less_50_k_prob*np.prod(np.array(probs_less_50K))\n",
    "    greater_50 = greater_50_k_prob*np.prod(np.array(np.prod(probs_greater_50K)))\n",
    "\n",
    "    # prediction is max of (probability of target)*(likelihood of y_value/attribute combination)\n",
    "    if less_50 > greater_50:\n",
    "        return '<=50'\n",
    "    else:\n",
    "        return '>50'\n",
    "    \n",
    "# make predcition\n",
    "predicted = naive_bays_classifier(income_evaluation_cat, 'income',\n",
    "                                  ['Private', 'Bachelors', 'White', 'Female'])\n",
    "# print prediction\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\tPreprocess or transform the features in the income_evaluation_cat.csv data using an appropriate scaler in sklearn. You don’t need to transform the output variable; it should still work fine in a text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "apply sklearn ordinal encoder to the data to allow fitting\n",
    "CategoricalNB estimator\n",
    "\"\"\"\n",
    "\n",
    "# get the columns\n",
    "cols = income_evaluation_cat.iloc[:, :-1].columns\n",
    "# instantiate ordinal encoder and fit_transform the data\n",
    "income_evaluation_cat[cols] = OrdinalEncoder().fit_transform(income_evaluation_cat[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)\tRandomly split the transformed input data and the output data into X_train, y_train, X_test and y_test using tools in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"us sklearn shuffle split to randomly split input and output data\"\"\"\n",
    "\n",
    "# separate the features and target\n",
    "X = income_evaluation_cat.iloc[:, :-1]\n",
    "y= income_evaluation_cat.iloc[:, -1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, shuffle=True,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)\tUse an appropriate Naïve Bayes constructor in sklearn to construct and fit a Naïve Bayes model on the training data, then use the model to compute the accuracy score of the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CategoricalNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalNB</label><div class=\"sk-toggleable__content\"><pre>CategoricalNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"construct categoricalNB estimator then fit to the data and score\"\"\"\n",
    "\n",
    "# construct the estimator\n",
    "cnb = CategoricalNB()\n",
    "# fit estimator to training set\n",
    "cnb.fit(X_train, y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7827746577746578"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute accuracy score on the training set\"\"\"\n",
    "\n",
    "# score against the training set\n",
    "cnb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7879005015866517"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute accuracy score on the test set\"\"\"\n",
    "\n",
    "# score against the training set\n",
    "cnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\tUpload the income_evaluation_continuous.csv data provided on canvas.  The features in this data include age, education_num, and hours_per_week. The output variable is income and contains two categorical values (<=50k or >50k) indicating whether the income of an individual is less than/equal to $50,000 or greater than $50,000 respectively. Compute the mean and standard deviation of each input variable such that the results are presented on the same table or data frame. You can call the .apply() function on the pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education_num  hours_per_week  income\n",
       "0   39             13              40   <=50K\n",
       "1   50             13              13   <=50K\n",
       "2   38              9              40   <=50K\n",
       "3   53              7              40   <=50K\n",
       "4   28             13              40   <=50K"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import the data and print the data head\"\"\"\n",
    "\n",
    "income_evaluation_continuous = pd.read_csv('income_evaluation_continuous.csv')\n",
    "income_evaluation_continuous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  education_num  hours_per_week\n",
       "mean  38.581647      10.080679       40.437456\n",
       "std   13.640433       2.572720       12.347429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute the mean and standard deviation of each input variable\"\"\"\n",
    "\n",
    "income_evaluation_continuous.iloc[:, :-1].agg(func=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"trim whitespace from column names\"\"\"\n",
    "\n",
    "income_evaluation_continuous.columns = income_evaluation_continuous.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\tYou will implement Naïve Bayes from scratch using Bayes’ rule. Assume that all the features or input variables follow a normal distribution. You can do your calculations in Python, but you would not use the sklearn package. You can use the density function inside the stats module in the SciPy package. Given that all the income_evaluation_continuous.csv data you uploaded is the training data , classify a test instance, X = [30, 10, 45], into the class income<=50 or income>50k. You need to compute the posterior probabilities P(income<=50/X) and P(income>50k/X), then print the class with the greater posterior probability as the predicted class. You don’t need to define a function, but you could if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<=50K'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"implement Gaussian Naive Bayes classifier\"\"\"\n",
    "\n",
    "def gaussian_nb(data, target, new_record):\n",
    "\n",
    "    # get the mean of input features by class\n",
    "    mean = data.groupby(target).mean()\n",
    "    mean_less_50K = mean.iloc[0]\n",
    "    mean_greater_50K = mean.iloc[1]\n",
    "    # get standard deviation of input features\n",
    "    std = data.groupby(target).std()\n",
    "    std_less_50K = std.iloc[0]\n",
    "    std_greater_50K = std.iloc[1]\n",
    "    # compute the probability density of features in new_record for each class\n",
    "    density_less_50K = stats.norm(mean_less_50K, std_less_50K).pdf(new_record)\n",
    "    density_greater_50K = stats.norm(mean_greater_50K, std_greater_50K).pdf(new_record)\n",
    "    # get the probabiity of each class label in the data\n",
    "    p_y = data[target].value_counts()/sum(data[target].value_counts())\n",
    "    y_less_50K = p_y[0]\n",
    "    y_greater_50K = p_y[1]\n",
    "    # compute the posterior probability of each class\n",
    "    posterior_less_50K = y_less_50K*np.prod(density_less_50K)\n",
    "    posterior_greater_50K = y_greater_50K*np.prod(density_greater_50K)\n",
    "    # return the class prediction\n",
    "    if posterior_less_50K > posterior_greater_50K:\n",
    "        return \"<=50K\"\n",
    "    else:\n",
    "        return \">50K\"\n",
    "\n",
    "# create a new record then make predictions\n",
    "new_record = [30, 10, 45]\n",
    "gaussian_nb(income_evaluation_continuous, 'income', new_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\tPreprocess or transform the features in the income_evaluation_cont.csv data using an appropriate scaler in sklearn. You don’t need to transform the output variable; it should still work fine in a text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"transform numeric features in the data using standard scaler\"\"\"\n",
    "\n",
    "# get input features in data\n",
    "inputs = income_evaluation_continuous.iloc[:, :-1].columns\n",
    "# instantiate standard scaler and fit_transform the data\n",
    "sc = StandardScaler()\n",
    "income_evaluation_continuous[inputs] = sc.fit_transform(income_evaluation_continuous[inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)\tRandomly split the input and output data into X_train, y_train, X_test and y_test using tools in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"randomly split the data into training and test sets\"\"\"\n",
    "\n",
    "X = income_evaluation_continuous.iloc[:, :-1]\n",
    "y= income_evaluation_continuous.iloc[:, -1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)\tUse an appropriate Naïve Bayes constructor in sklearn to construct and fit a Naïve Bayes model on the training data, then use the model to compute the accuracy score of the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"implement GaussianNB estimator, sklearn\"\"\"\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7993594243594243"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute the accuracy score on the training set\"\"\"\n",
    "\n",
    "gnb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988535162247927"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute the accuracy score on the test set\"\"\"\n",
    "\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\tUpload the True.csv data provided on canvas into Python. You will create a new data frame by selecting the “title” and “text” columns, then, adding a new column called “news_type” where all the values on this new column are “True”. So, your new data frame should have three columns; “title”, “text” and “news_type”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"upload the data, keep necessary columns, add new column news_type\"\"\"\n",
    "\n",
    "# upload the data \n",
    "true = pd.read_csv('True.csv', usecols=['title', 'text'])\n",
    "true['news_type'] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\tUpload the Fake.csv data provided on canvas into Python. You will create a new data frame by selecting the “title” and “text” columns, then, adding a new column called “news_type” where all the values on this new column are “Fake”. So, your new data frame should have three columns; “title”, “text” and “news_type”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"upload the data, keep necessary columns, add new column news_type\"\"\"\n",
    "\n",
    "# upload the data \n",
    "fake = pd.read_csv('Fake.csv', usecols=['title', 'text'])\n",
    "fake['news_type'] = \"False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\tMerge the data frame in a) and b) so that one of the data frames is stacked vertically on top of the other. Combine the text in the “title” and “text” columns of the merged data frame into another column called “news”. Drop the “title” and “text” columns so that your final data frame is has only two columns, “news” and “news_type”. Print the first five rows of your final data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news news_type\n",
       "0  As U.S. budget fight looms, Republicans flip t...      True\n",
       "1  U.S. military to accept transgender recruits o...      True\n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...      True\n",
       "3  FBI Russia probe helped by Australian diplomat...      True\n",
       "4  Trump wants Postal Service to charge 'much mor...      True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "stack the data, combine the text in the title and text columns,\n",
    "then drop the title and text columns\n",
    "\"\"\"\n",
    "\n",
    "# stack the data\n",
    "news = pd.concat([true, fake], ignore_index=True)\n",
    "# insert the new column\n",
    "news.insert(loc=0, column='news', value=news.apply(lambda x: x['title'] + \" \" + x['text'], axis=1))\n",
    "# drop the unnecessary columns\n",
    "news.drop(columns=['title', 'text'], inplace=True)\n",
    "# print the first 5 rows of data\n",
    "news.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)\tPreprocess your data by cleaning the textual data in the “news” column and removing the stop words, special characters, punctuations, etc especially at the beginning and end of each word. You can display any messy news text before you clean the data, then display the messy news text again after cleaning the data to see if your data cleaning worked well. Also, drop instances where the news text is less than 50 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"define a functiion to clean text data\"\"\"\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # remove all non-alphanumeric characters while preserving spaces\n",
    "    text = re.sub(r'[^a-zA-Z0-9 //g]', '', text)\n",
    "    # get text as a list of words\n",
    "    text = text.split()\n",
    "    # remove all stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    cleaner_text = [word.lower() for word in text if word.lower() not in stop_words]\n",
    "    # check the length of cleaner text, if len(cleaner_text < 50) return false\n",
    "    if len(cleaner_text) >= 50:\n",
    "        return \" \".join(cleaner_text)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     As U.S. budget fight looms, Republicans flip t...\n",
       "1     U.S. military to accept transgender recruits o...\n",
       "2     Senior U.S. Republican senator: 'Let Mr. Muell...\n",
       "3     FBI Russia probe helped by Australian diplomat...\n",
       "4     Trump wants Postal Service to charge 'much mor...\n",
       "5     White House, Congress prepare for talks on spe...\n",
       "6     Trump says Russia probe will be fair, but time...\n",
       "7     Factbox: Trump on Twitter (Dec 29) - Approval ...\n",
       "8     Trump on Twitter (Dec 28) - Global Warming The...\n",
       "9     Alabama official to certify Senator-elect Jone...\n",
       "10    Jones certified U.S. Senate winner despite Moo...\n",
       "11    New York governor questions the constitutional...\n",
       "12    Factbox: Trump on Twitter (Dec 28) - Vanity Fa...\n",
       "13    Trump on Twitter (Dec 27) - Trump, Iraq, Syria...\n",
       "14    Man says he delivered manure to Mnuchin to pro...\n",
       "15    Virginia officials postpone lottery drawing to...\n",
       "16    U.S. lawmakers question businessman at 2016 Tr...\n",
       "17    Trump on Twitter (Dec 26) - Hillary Clinton, T...\n",
       "18    U.S. appeals court rejects challenge to Trump ...\n",
       "19    Treasury Secretary Mnuchin was sent gift-wrapp...\n",
       "20    Federal judge partially lifts Trump's latest r...\n",
       "21    Exclusive: U.S. memo weakens guidelines for pr...\n",
       "22    Trump travel ban should not apply to people wi...\n",
       "23    Second court rejects Trump bid to stop transge...\n",
       "24    Failed vote to oust president shakes up Peru's...\n",
       "25    Trump signs tax, government spending bills int...\n",
       "26    Companies have up to a year for new U.S. tax b...\n",
       "27    Trump on Twitter (Dec 22) - Tax cut, Missile d...\n",
       "28    Mexico to review need for tax changes after U....\n",
       "29    Senate leader McConnell sees a more collegial ...\n",
       "30    Alabama to certify Democrat Jones winner of Se...\n",
       "31    McConnell happier with Trump tweets after tax ...\n",
       "32    House panel asks Trump ex-top aide Bannon to t...\n",
       "33    Callista Gingrich becomes Trump's envoy to pop...\n",
       "34    As Republicans aim to ride economy to election...\n",
       "35    Exclusive: State Department tells refugee agen...\n",
       "36    Congress votes to avert shutdown, sends Trump ...\n",
       "37    Factbox: Big-ticket items at center of Congres...\n",
       "38    In victory for Trump, judge tosses suit on for...\n",
       "39    Senate shelves disaster aid bill until next mo...\n",
       "40    Trump on Twitter (Dec 21) - Tax Cuts, Home sal...\n",
       "41    House widens ethics probe to include Farenthol...\n",
       "42    U.S. court rejects Trump bid to stop transgend...\n",
       "43    U.S. House approves $81 billion for disaster a...\n",
       "44    House Democrats rally to protect Special Couns...\n",
       "45    Second U.S. judge blocks Trump administration ...\n",
       "46    Senators seek to stop expansion of airport fac...\n",
       "47    U.S. launches effort to reduce reliance on imp...\n",
       "48    Short-term government funding, disaster aid bi...\n",
       "49    Spy chiefs pressure Congress to renew expiring...\n",
       "50    Trump urges Congress to pass short-term spendi...\n",
       "Name: news, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print some text prior to cleaning\"\"\"\n",
    "\n",
    "news['news'][0:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"apply the clean_text function to the data\"\"\"\n",
    "\n",
    "news['news'] = news['news'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     us budget fight looms republicans flip fiscal ...\n",
       "1     us military accept transgender recruits monday...\n",
       "2     senior us republican senator let mr mueller jo...\n",
       "3     fbi russia probe helped australian diplomat ti...\n",
       "4     trump wants postal service charge much amazon ...\n",
       "5     white house congress prepare talks spending im...\n",
       "6     trump says russia probe fair timeline unclear ...\n",
       "7     factbox trump twitter dec 29 approval rating a...\n",
       "8     trump twitter dec 28 global warming following ...\n",
       "9     alabama official certify senatorelect jones to...\n",
       "10    jones certified us senate winner despite moore...\n",
       "11    new york governor questions constitutionality ...\n",
       "12    factbox trump twitter dec 28 vanity fair hilla...\n",
       "13    trump twitter dec 27 trump iraq syria followin...\n",
       "14    man says delivered manure mnuchin protest new ...\n",
       "15    virginia officials postpone lottery drawing de...\n",
       "16    us lawmakers question businessman 2016 trump t...\n",
       "17    trump twitter dec 26 hillary clinton tax cut b...\n",
       "18    us appeals court rejects challenge trump voter...\n",
       "19    treasury secretary mnuchin sent giftwrapped bo...\n",
       "20    federal judge partially lifts trumps latest re...\n",
       "21    exclusive us memo weakens guidelines protectin...\n",
       "22    trump travel ban apply people strong us ties c...\n",
       "23    second court rejects trump bid stop transgende...\n",
       "24    failed vote oust president shakes perus politi...\n",
       "25    trump signs tax government spending bills law ...\n",
       "26    companies year new us tax bill reporting sec w...\n",
       "27    trump twitter dec 22 tax cut missile defense b...\n",
       "28                                                 None\n",
       "29    senate leader mcconnell sees collegial 2018 wa...\n",
       "30    alabama certify democrat jones winner senate e...\n",
       "31    mcconnell happier trump tweets tax victory was...\n",
       "32    house panel asks trump extop aide bannon testi...\n",
       "33    callista gingrich becomes trumps envoy pope di...\n",
       "34    republicans aim ride economy election victory ...\n",
       "35    exclusive state department tells refugee agenc...\n",
       "36    congress votes avert shutdown sends trump stop...\n",
       "37    factbox bigticket items center congress spendi...\n",
       "38    victory trump judge tosses suit foreign paymen...\n",
       "39    senate shelves disaster aid bill next month wa...\n",
       "40    trump twitter dec 21 tax cuts home sales follo...\n",
       "41    house widens ethics probe include farenthold c...\n",
       "42    us court rejects trump bid stop transgender mi...\n",
       "43                                                 None\n",
       "44    house democrats rally protect special counsel ...\n",
       "45    second us judge blocks trump administration bi...\n",
       "46    senators seek stop expansion airport facial sc...\n",
       "47    us launches effort reduce reliance imports cri...\n",
       "48    shortterm government funding disaster aid bill...\n",
       "49    spy chiefs pressure congress renew expiring su...\n",
       "50    trump urges congress pass shortterm spending b...\n",
       "Name: news, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print some text following cleaning\"\"\"\n",
    "\n",
    "news['news'][0:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3250"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "check for null values returned by clean_text function\n",
    "these represent text shorter than 50 words and should be dropped\n",
    "\"\"\"\n",
    "\n",
    "news['news'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news         0\n",
       "news_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"drop rows with null values\"\"\"\n",
    "\n",
    "news.dropna(axis=0,inplace=True)\n",
    "news.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)\tTransform the input text data into feature vectors where the entries of the feature vectors are term-frequency-inverse-document-frequency. Use the TfidfVectorizer() in sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"get document feature vectors using sklearn\"\"\"\n",
    "\n",
    "# instantiate TfidfVectorizer sklearn\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', min_df=10, max_features=None)\n",
    "# get document vectors\n",
    "document_vectors = tfidf.fit_transform(news['news'])\n",
    "document_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f)\tSplit the feature vectors and the output variable into into X_train, y_train, X_test and y_test, you can let the test set be 30% of the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create the training and test sets\"\"\"\n",
    "\n",
    "# get input feature vectors and target output\n",
    "X = news.iloc[:, :-1]\n",
    "y = news.iloc[:, -1:] \n",
    "# create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, shuffle=True, random_state=42)\n",
    "# instantiate TfidfVectorizer sklearn\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', min_df=10, max_features=None)\n",
    "# get training and test document vectors\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['news'])\n",
    "X_test_tfidf = tfidf.transform(X_test['news'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g)\tFit an appropriate Naïve Bayes model and compute the training and test accuracy of the model. Is there overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"fit a multinomial Naive Bayes estimator sklearn\"\"\"\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630226734812883"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute accuracy score for training set\"\"\"\n",
    "\n",
    "mnb.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544617847138855"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute accuracy score for test set\"\"\"\n",
    "\n",
    "mnb.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multinomial Naive Bayes Model performed well on both the training and test sets, with nearly equivalent accuracy scores. Based on these results there does not appear to be a problem with overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h)\tFit a Naïve Bayes using cross validation and print the average cross validation score as well as the standard deviation of the cross-validation scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cross-validation accuracy score is:  0.9546873720500213\n",
      "The standard deviation of cross-validation scores is:  0.0015806293159337996\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "fit the mulitnomial Naive Bayes Mmdel using cross validation\n",
    "print the mean and standard deviation of cross-validation scores\n",
    "\"\"\"\n",
    "\n",
    "# get cross-validation scores\n",
    "cross_val_scores = cross_val_score(estimator=MultinomialNB(), X=X_train_tfidf,\n",
    "                                   y=y_train.to_numpy().flatten(), cv=3)\n",
    "# print mean and standard deviation of scores\n",
    "print(\"The average cross-validation accuracy score is: \", cross_val_scores.mean())\n",
    "print(\"The standard deviation of cross-validation scores is: \", cross_val_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i)\tSelect some hypermeters of your choice and tune using the grid search cross validation. Use some other hyperparameters than those used in class examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(lowercase=False,\n",
       "                                                        stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             param_grid=[{&#x27;tfidf__norm&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;tfidf__sublinear_tf&#x27;: [True, False]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(lowercase=False,\n",
       "                                                        stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             param_grid=[{&#x27;tfidf__norm&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;tfidf__sublinear_tf&#x27;: [True, False]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(lowercase=False, stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(lowercase=False, stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(lowercase=False,\n",
       "                                                        stop_words='english')),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid=[{'tfidf__norm': ['l1', 'l2'],\n",
       "                          'tfidf__sublinear_tf': [True, False]}])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"isntantiate sklearn pipeline and GridSearchCV\"\"\"\n",
    "\n",
    "# create the pipeline\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words='english', lowercase=False)), \n",
    "                    ('mnb', MultinomialNB())])\n",
    "# specify param grid for tfidf and model\n",
    "params = [{'tfidf__sublinear_tf': [True, False], 'tfidf__norm': ['l1', 'l2']}]\n",
    "# instantiate and fit grid\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=params, cv=3)\n",
    "grid_search.fit(X_train['news'], y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print the best parameters\"\"\"\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577401982643295"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print accuracy score on training data\"\"\"\n",
    "\n",
    "grid_search.score(X_train['news'], y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9471788715486195"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print accuracy score on test data\"\"\"\n",
    "\n",
    "grid_search.score(X_test['news'], y_test.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find some text data of your own choice, it could be labelled tweets, etc. \n",
    "Your dataset should have at least 200 instances, and if there are several columns of text, you can choose to merge the text columns into a single text column. Each text instance should have at least 60 words.\n",
    " \n",
    "Clean the data, split the data, transform the data to a representation suitable for your algorithm, build your model and evaluate the model. Tune some parameters of interest and write a short report about what problem your mini project is trying to address, the description of your data, the choice of algorithm used, the performance of your algorithm, overfitting, the choice of hyperparameters tunned, then your recommendation or conclusion (imagine you were trying to recommend this algorithm to a stakeholder, and you need this report to include important and persuasive elements). Your report could be in one or two paragraphs and should include relevant code and output at the end. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Food Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                Summary  \\\n",
       "0      5  Good Quality Dog Food   \n",
       "1      1      Not as Advertised   \n",
       "2      4  \"Delight\" says it all   \n",
       "3      2         Cough Medicine   \n",
       "4      5            Great taffy   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"read in the reviews data\"\"\"\n",
    "\n",
    "reviews = pd.read_csv('reviews.csv', usecols=['Text', 'Score', 'Summary'], nrows=25000)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"combine the Summary and Text Columns then drop original\"\"\"\n",
    "\n",
    "reviews.insert(loc=0, column='Review', value=reviews.apply(lambda x: x['Summary'] + \" \" + x['Text'], axis=1))\n",
    "reviews.drop(columns=['Summary', 'Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create new target feature \"review_sentiment\" \"\"\"\n",
    "\n",
    "reviews.insert(loc=2, column='review_sentiment', value=reviews.apply(lambda x: 'positive' if (x['Score'] > 3) else 'negative', axis=1))\n",
    "reviews.drop(columns=['Score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"define a functiion to clean reviews\"\"\"\n",
    "\n",
    "def clean_reviews(text):\n",
    "\n",
    "    # remove all non-alphanumeric characters while preserving spaces, @, and #\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # get text as a list of words\n",
    "    text = text.split()\n",
    "    # remove all stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    cleaner_text = [word.lower() for word in text if word.lower() not in stop_words]\n",
    "     # check the length of cleaner text, if len(cleaner_text < 60) return false\n",
    "    if len(cleaner_text) >= 60:\n",
    "        return \" \".join(cleaner_text)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Good Quality Dog Food I have bought several of...\n",
       "1     Not as Advertised Product arrived labeled as J...\n",
       "2     \"Delight\" says it all This is a confection tha...\n",
       "3     Cough Medicine If you are looking for the secr...\n",
       "4     Great taffy Great taffy at a great price.  The...\n",
       "5     Nice Taffy I got a wild hair for taffy and ord...\n",
       "6     Great!  Just as good as the expensive brands! ...\n",
       "7     Wonderful, tasty taffy This taffy is so good. ...\n",
       "8     Yay Barley Right now I'm mostly just sprouting...\n",
       "9     Healthy Dog Food This is a very healthy dog fo...\n",
       "10    The Best Hot Sauce in the World I don't know i...\n",
       "11    My cats LOVE this \"diet\" food better than thei...\n",
       "12    My Cats Are Not Fans of the New Food My cats h...\n",
       "13    fresh and greasy! good flavor! these came secu...\n",
       "14    Strawberry Twizzlers - Yummy The Strawberry Tw...\n",
       "15    Lots of twizzlers, just what you expect. My da...\n",
       "16    poor taste I love eating them and they are goo...\n",
       "17    Love it! I am very satisfied with my Twizzler ...\n",
       "18    GREAT SWEET CANDY! Twizzlers, Strawberry my ch...\n",
       "19    Home delivered twizlers Candy was delivered ve...\n",
       "20    Always fresh My husband is a Twizzlers addict....\n",
       "21    TWIZZLERS I bought these for my husband who is...\n",
       "22    Delicious product! I can remember buying this ...\n",
       "23    Twizzlers I love this candy.  After weight wat...\n",
       "24    Please sell these in Mexico!! I have lived out...\n",
       "25    Twizzlers - Strawberry Product received is as ...\n",
       "26    Nasty No flavor The candy is just red , No fla...\n",
       "27    Great Bargain for the Price I was so glad Amaz...\n",
       "28    YUMMY! I got this for my Mum who is not diabet...\n",
       "29    The Best Hot Sauce in the World I don't know i...\n",
       "30    Great machine! I have never been a huge coffee...\n",
       "31    THIS IS MY TASTE... This offer is a great pric...\n",
       "32    Best of the Instant Oatmeals McCann's Instant ...\n",
       "33    Good Instant This is a good instant oatmeal fr...\n",
       "34    Great Irish oatmeal for those in a hurry! Inst...\n",
       "35    satisfying McCann's Instant Irish Oatmeal, Var...\n",
       "36    Love Gluten Free Oatmeal!!! For those of us wi...\n",
       "37    it's oatmeal What else do you need to know? Oa...\n",
       "38    GOOD WAY TO START THE DAY.... I WAS VISITING M...\n",
       "39    Wife's favorite Breakfast I ordered this for m...\n",
       "40    Why wouldn't you buy oatmeal from Mcanns? Tast...\n",
       "41    Oatmeal For Oatmeal Lovers McCann's makes oatm...\n",
       "42    Food-Great I have McCann's Oatmeal every morni...\n",
       "43    Good Hot Breakfast McCann's Oatmeal is a good ...\n",
       "44    Great taste and convenience We really like the...\n",
       "45    Hearty Oatmeal This seems a little more wholes...\n",
       "46    good Good oatmeal.  I like the apple cinnamon ...\n",
       "47    Mushy The flavors are good.  However, I do not...\n",
       "48    Very good but next time I won't order the Vari...\n",
       "49    Same stuff This is the same stuff you can buy ...\n",
       "50    Don't like it This oatmeal is not good. Its mu...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"print some reviews prior to cleaning\"\n",
    "\n",
    "reviews['Review'][0:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"clean reviews text\"\"\"\n",
    "\n",
    "reviews['Review'] = reviews['Review'].apply(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  None\n",
       "1                                                  None\n",
       "2                                                  None\n",
       "3                                                  None\n",
       "4                                                  None\n",
       "5                                                  None\n",
       "6                                                  None\n",
       "7                                                  None\n",
       "8                                                  None\n",
       "9                                                  None\n",
       "10    best hot sauce world dont know cactus tequila ...\n",
       "11                                                 None\n",
       "12                                                 None\n",
       "13                                                 None\n",
       "14                                                 None\n",
       "15                                                 None\n",
       "16                                                 None\n",
       "17                                                 None\n",
       "18    great sweet candy twizzlers strawberry childho...\n",
       "19                                                 None\n",
       "20                                                 None\n",
       "21                                                 None\n",
       "22                                                 None\n",
       "23                                                 None\n",
       "24                                                 None\n",
       "25                                                 None\n",
       "26                                                 None\n",
       "27                                                 None\n",
       "28                                                 None\n",
       "29    best hot sauce world dont know cactus tequila ...\n",
       "30                                                 None\n",
       "31                                                 None\n",
       "32    best instant oatmeals mccanns instant oatmeal ...\n",
       "33                                                 None\n",
       "34    great irish oatmeal hurry instant oatmeal beco...\n",
       "35                                                 None\n",
       "36                                                 None\n",
       "37                                                 None\n",
       "38                                                 None\n",
       "39                                                 None\n",
       "40    wouldnt buy oatmeal mcanns tastes great variet...\n",
       "41    oatmeal oatmeal lovers mccanns makes oatmeal e...\n",
       "42                                                 None\n",
       "43                                                 None\n",
       "44                                                 None\n",
       "45                                                 None\n",
       "46                                                 None\n",
       "47                                                 None\n",
       "48                                                 None\n",
       "49                                                 None\n",
       "50                                                 None\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"print some reviews following cleaning\"\n",
    "\n",
    "reviews['Review'][0:51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19699"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "check for null values returned by clean_tweet function\n",
    "these represent text shorter than 60 words and should be dropped\n",
    "\"\"\"\n",
    "\n",
    "reviews['Review'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review              0\n",
       "review_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"drop rows with null values\"\"\"\n",
    "\n",
    "reviews.dropna(axis=0,inplace=True)\n",
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"split the data into training and test sets\"\"\"\n",
    "\n",
    "# get input feature vectors and target output\n",
    "X = reviews.iloc[:, :-1]\n",
    "y = reviews.iloc[:, -1:] \n",
    "# create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, shuffle=True, random_state=42)\n",
    "# instantiate TfidfVectorizer sklearn\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', min_df=5, max_features=None)\n",
    "# get training and test document vectors\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['Review'])\n",
    "X_test_tfidf = tfidf.transform(X_test['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"fit multinomial Naive Bayes model to the data\"\"\"\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609164420485175"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute accuracy score for training set\"\"\"\n",
    "\n",
    "mnb.score(X_train_tfidf, y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7177875549968573"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"compute accuracy score on test data\"\"\"\n",
    "\n",
    "mnb.score(X_test_tfidf, y_test.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             param_grid=[{&#x27;tfidf__min_df&#x27;: [1, 5, 10, 20],\n",
       "                          &#x27;tfidf__norm&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;tfidf__sublinear_tf&#x27;: [True, False]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;mnb&#x27;, MultinomialNB())]),\n",
       "             param_grid=[{&#x27;tfidf__min_df&#x27;: [1, 5, 10, 20],\n",
       "                          &#x27;tfidf__norm&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;tfidf__sublinear_tf&#x27;: [True, False]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;mnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('mnb', MultinomialNB())]),\n",
       "             param_grid=[{'tfidf__min_df': [1, 5, 10, 20],\n",
       "                          'tfidf__norm': ['l1', 'l2'],\n",
       "                          'tfidf__sublinear_tf': [True, False]}])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"isntantiate sklearn pipeline and GridSearchCV\"\"\"\n",
    "\n",
    "# create the pipeline\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), \n",
    "                    ('mnb', MultinomialNB())])\n",
    "# specify param grid for tfidf and model\n",
    "params = [{'tfidf__min_df': [1, 5, 10, 20], 'tfidf__norm': ['l1', 'l2'], 'tfidf__sublinear_tf': [True, False]}]\n",
    "# instantiate and fit grid\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=params, cv=3)\n",
    "grid_search.fit(X_train['Review'], y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__min_df': 20, 'tfidf__norm': 'l2', 'tfidf__sublinear_tf': True}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print the best parameters\"\"\"\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018867924528302"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"make predictions on the training set\"\"\"\n",
    "\n",
    "grid_search.score(X_train['Review'], y_train.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7592708988057826"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"make predictions on the test set\"\"\"\n",
    "\n",
    "grid_search.score(X_test['Review'], y_test.to_numpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('COMP4448-zVXvr8KM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5392b5f59a5fef62b4badd3fb41b4c3fb016ca90199b117ded7058284d432eca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
