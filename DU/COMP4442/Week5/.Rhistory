knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(HistData)
data("Guerry")
dat<-Guerry
dat.c<-filter(dat,Region=="C")
(g<-ggplot(data=dat.c,aes(x=Commerce,y=Wealth))+geom_point())
w<-dat.c$Wealth
c<-dat.c$Commerce
n<-nrow(dat.c)
(m<-(sum(c*w)/n-mean(c)*mean(w))/
(sum((c)^2)/n-mean(c)^2))
(b<-mean(w)-m*mean(c))
(g+geom_abline(slope=m, intercept=b))
setwd("~/OneDrive - University of Denver/COMP4442/ProblemSetsWorkingDirectory/Week5")
knitr::opts_chunk$set(echo = TRUE)
# load necessary libraries
library(tidyverse)
library(lmtest) # For lrtest()
library(ggplot2)
# function to compute probability from odds
prob.from.odds <- function(b){
p <- b/(1+b)
return(p)
}
# five
five <- prob.from.odds(5)
# ten
ten <- prob.from.odds(10)
# fifteen
fifteen <- prob.from.odds(15)
# print probabilities
five
ten
fifteen
# create dataframe of integers 0-20
prob.df <-data.frame(odds = seq.int(0,20,1))
# apply function to calculate probs
prob.df$probs <- apply(prob.df, 1, prob.from.odds)
# Create prob_plt
prob_plt <- ggplot(prob.df, aes(x=odds, y=probs))+
geom_point()+
ylab("Probabilities")+
scale_x_continuous(breaks = seq.int(0, 20, 1))
prob_plt
# load and subset the data
load("pew_data.RData")
pew<-dplyr::select(dat,PPINCIMP,PPGENDER,PPETHM,IDEO,PPEDUCAT,LIFE)
# view questions and attributes
attributes(pew$LIFE)$label # LIFE
attributes(pew$LIFE)$labels
table(pew$LIFE, exclude = NULL)
attributes(pew$PPINCIMP)$label #income
attributes(pew$PPINCIMP)$labels
table(pew$PPINCIMP, exclude = NULL)
attributes(pew$PPGENDER)$label #gender
attributes(pew$PPGENDER)$labels
table(pew$PPGENDER, exclude = NULL)
attributes(pew$PPETHM)$label #ethnicity
attributes(pew$PPETHM)$labels
table(pew$PPETHM, exclude = NULL)
attributes(pew$IDEO)$label #ideology
attributes(pew$IDEO)$labels
table(pew$IDEO, exclude = NULL)
attributes(pew$PPEDUCAT)$label #education
attributes(pew$PPEDUCAT)$labels
table(pew$PPEDUCAT, exclude = NULL)
# create pew.complete
pew.complete <- pew
# drop any NA's  (I don't believe there were any but caution)
pew.complete %>% drop_na()
# check for values of -1 in life
which(pew.complete$LIFE == -1 , arr.ind = TRUE)
# check for values of -2 in life
which(pew.complete$LIFE == -2 , arr.ind = TRUE)
#check for values of -1 in IDEO
which(pew.complete$IDEO == -1 , arr.ind = TRUE)
# check for values of -2 in IDEO
which(pew.complete$IDEO == -2 , arr.ind = TRUE)
# remove rows containing -1 or -2
#pew.complete <- filter(pew.complete, LIFE != -1, IDEO != -1 )
pew.complete <- filter_all(pew.complete, all_vars(. != -1))
pew.complete <- filter_all(pew.complete, all_vars(. != -2))
# print num rows in each dataframe
nrow(pew)
nrow(pew.complete)
# LIFE
table(pew.complete$LIFE, exclude = NULL)
# PPINCIMP
table(pew.complete$PPINCIMP, exclude = NULL)
# PPGENDER
table(pew.complete$PPGENDER, exclude = NULL)
#PPETHM
table(pew.complete$PPETHM, exclude = NULL)
#IDEO
table(pew.complete$IDEO, exclude = NULL)
#PPEDUCAT
table(pew.complete$PPEDUCAT, exclude = NULL)
# re-code the outcome variable
pew.complete$worse <- as.factor(ifelse(pew.complete$LIFE == 2, 1, 0))
# display the frequencies of the recoded outcome
table(pew.complete$worse, exclude = NULL)
# set variables to the appropriate type
pew.complete$income <- as.numeric(pew.complete$PPINCIMP)
pew.complete$gender <- as.factor(pew.complete$PPGENDER)
pew.complete$eth <- as.factor(pew.complete$PPETHM)
pew.complete$ideo <- as.factor(pew.complete$IDEO)
pew.complete$edu <- as.factor(pew.complete$PPEDUCAT)
pew.complete$worse <- as.factor(pew.complete$worse)
# print data structure
str(pew.complete)
# create glm (binomial)
Model.1 <- glm(worse ~ income+gender,
data=pew.complete, family="binomial")
# print model summary
summary(Model.1)
# create glm (binomial)
Model.2 <- glm(worse ~ income+gender+eth+edu,
data=pew.complete, family="binomial")
# print model summary
summary(Model.2)
# create glm (binomial)
Model.3 <- glm(worse ~ income+gender+eth+edu+ideo,
data=pew.complete, family="binomial")
summary(Model.3)
# alternate method
#anova(Model.1, Model.2, test = "LRT")
# conduct lrttest
lrtest(Model.1, Model.2)
# alternate method
#anova(Model.2, Model.3, test = "LRT")
# conduct lrtest
lrtest(Model.2, Model.3)
# Code to produce the 0/1 predicted values
prediction <- predict(Model.3,pew.complete, type="response")
# binarize the outcome
prediction <- as.factor(ifelse(prediction > 0.5, 1, 0))
# create tables to show actuals and predicted
actuals <- table(pew.complete$worse)
predicted <- table(prediction)
actuals
predicted
# create the confusion matrix using table function
confusion.matrix <- table(pew.complete$worse,prediction)
# print the confusion matrix
confusion.matrix
# create the confusion matrix using table function
confusion.matrix <- table(pew.complete$worse,prediction)
# print the confusion matrix
confusion.matrix
# compute the accuracy of the model
# true positives and true negatives are on the diagonals
accuracy <- sum(diag(confusion.matrix))/sum(confusion.matrix)
# compute precision
# (true positive/(true positive + false positive))
precision <- confusion.matrix[2,2]/sum(confusion.matrix[,2])
# Code to compute recall
# (true positive/(true positive + false negative)
recall <- confusion.matrix[2,2]/sum(confusion.matrix[2,]) # Again,
# compute F1 score
F1 <- 2*((precision*recall)/(precision+recall))
knitr::opts_chunk$set(echo = TRUE)
# load necessary libraries
library(tidyverse)
library(lmtest) # For lrtest()
library(ggplot2)
# function to compute probability from odds
prob.from.odds <- function(b){
p <- b/(1+b)
return(p)
}
# five
five <- prob.from.odds(5)
# ten
ten <- prob.from.odds(10)
# fifteen
fifteen <- prob.from.odds(15)
# print probabilities
five
ten
fifteen
# create dataframe of integers 0-20
prob.df <-data.frame(odds = seq.int(0,20,1))
# apply function to calculate probs
prob.df$probs <- apply(prob.df, 1, prob.from.odds)
# Create prob_plt
prob_plt <- ggplot(prob.df, aes(x=odds, y=probs))+
geom_point()+
ylab("Probabilities")+
scale_x_continuous(breaks = seq.int(0, 20, 1))
prob_plt
# load and subset the data
load("pew_data.RData")
pew<-dplyr::select(dat,PPINCIMP,PPGENDER,PPETHM,IDEO,PPEDUCAT,LIFE)
# view questions and attributes
attributes(pew$LIFE)$label # LIFE
attributes(pew$LIFE)$labels
table(pew$LIFE, exclude = NULL)
attributes(pew$PPINCIMP)$label #income
attributes(pew$PPINCIMP)$labels
table(pew$PPINCIMP, exclude = NULL)
attributes(pew$PPGENDER)$label #gender
attributes(pew$PPGENDER)$labels
table(pew$PPGENDER, exclude = NULL)
attributes(pew$PPETHM)$label #ethnicity
attributes(pew$PPETHM)$labels
table(pew$PPETHM, exclude = NULL)
attributes(pew$IDEO)$label #ideology
attributes(pew$IDEO)$labels
table(pew$IDEO, exclude = NULL)
attributes(pew$PPEDUCAT)$label #education
attributes(pew$PPEDUCAT)$labels
table(pew$PPEDUCAT, exclude = NULL)
# create pew.complete
pew.complete <- pew
# drop any NA's  (I don't believe there were any but caution)
pew.complete %>% drop_na()
# remove rows containing -1 or -2
#pew.complete <- filter(pew.complete, LIFE != -1, IDEO != -1 )
pew.complete <- filter_all(pew.complete, all_vars(. != -1))
pew.complete <- filter_all(pew.complete, all_vars(. != -2))
# print num rows in each dataframe
nrow(pew)
nrow(pew.complete)
# LIFE
table(pew.complete$LIFE, exclude = NULL)
# PPINCIMP
table(pew.complete$PPINCIMP, exclude = NULL)
# PPGENDER
table(pew.complete$PPGENDER, exclude = NULL)
#PPETHM
table(pew.complete$PPETHM, exclude = NULL)
#IDEO
table(pew.complete$IDEO, exclude = NULL)
#PPEDUCAT
table(pew.complete$PPEDUCAT, exclude = NULL)
# re-code the outcome variable
pew.complete$worse <- as.factor(ifelse(pew.complete$LIFE == 2, 1, 0))
# display the frequencies of the recoded outcome
table(pew.complete$worse, exclude = NULL)
# set variables to the appropriate type
pew.complete$income <- as.numeric(pew.complete$PPINCIMP)
pew.complete$gender <- as.factor(pew.complete$PPGENDER)
pew.complete$eth <- as.factor(pew.complete$PPETHM)
pew.complete$ideo <- as.factor(pew.complete$IDEO)
pew.complete$edu <- as.factor(pew.complete$PPEDUCAT)
pew.complete$worse <- as.factor(pew.complete$worse)
# print data structure
str(pew.complete)
# create glm (binomial)
Model.1 <- glm(worse ~ income+gender,
data=pew.complete, family="binomial")
# print model summary
summary(Model.1)
# create glm (binomial)
Model.2 <- glm(worse ~ income+gender+eth+edu,
data=pew.complete, family="binomial")
# print model summary
summary(Model.2)
# create glm (binomial)
Model.3 <- glm(worse ~ income+gender+eth+edu+ideo,
data=pew.complete, family="binomial")
summary(Model.3)
# alternate method
#anova(Model.1, Model.2, test = "LRT")
# conduct lrttest
lrtest(Model.1, Model.2)
# alternate method
#anova(Model.2, Model.3, test = "LRT")
# conduct lrtest
lrtest(Model.2, Model.3)
# create prediction
prediction <- predict(Model.3,pew.complete, type="response")
# binarize the outcome
prediction <- as.factor(ifelse(prediction > 0.5, 1, 0))
# create tables to show actuals and predicted
actuals <- table(pew.complete$worse)
predicted <- table(prediction)
actuals
predicted
# create the confusion matrix using table function
confusion.matrix <- table(pew.complete$worse,prediction)
# print the confusion matrix
confusion.matrix
# compute the accuracy of the model
# true positives and true negatives are on the diagonals
accuracy <- sum(diag(confusion.matrix))/sum(confusion.matrix)
# compute precision
# (true positive/(true positive + false positive))
precision <- confusion.matrix[2,2]/sum(confusion.matrix[,2])
# Code to compute recall
# (true positive/(true positive + false negative)
recall <- confusion.matrix[2,2]/sum(confusion.matrix[2,]) # Again,
# compute F1 score
F1 <- 2*((precision*recall)/(precision+recall))
